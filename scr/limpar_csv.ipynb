{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f440e527-028a-49ac-b1b9-fdb57cce4b78",
   "metadata": {},
   "source": [
    "# LIMPAR CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbe9b9-306d-4cde-857f-2b83a0343694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Módulo para processamento de dados climáticos em formato EPW e INMET.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "epw_folder = '../epw_raw/'\n",
    "inmet_folder = '../inmet_raw/'\n",
    "export_folder = '../climate_csv/'\n",
    "\n",
    "def epw_to_pandas(epw_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Converte arquivo EPW para DataFrame pandas com tratamento de erros.\n",
    "\n",
    "    Args:\n",
    "        epw_path (str): Caminho do arquivo .epw\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: DataFrame com dados ou None se erro\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Se arquivo não existir\n",
    "        ValueError: Se extensão for inválida\n",
    "    \"\"\"\n",
    "    path = Path(epw_path)\n",
    "    \n",
    "    # Validações iniciais\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {epw_path}\")\n",
    "    if path.suffix.lower() != \".epw\":\n",
    "        raise ValueError(\"Extensão inválida. Esperado .epw\")\n",
    "\n",
    "    # Mapeamento de colunas\n",
    "    columns = [\n",
    "        'Year', 'Month', 'Day', 'Hour[1-24]', 'Minute', 'Source flags',\n",
    "        'Dry Bulb Temperature', 'Dew_Point Temperature', 'Relative Humidity',\n",
    "        'Atmospheric Station Pressure', 'Extraterrestrial Horizontal Radiation',\n",
    "        'Extraterrestrial Direct Normal Radiation',\n",
    "        'Horizontal Infrared Radiation Intensity', 'Global Horizontal Radiation',\n",
    "        'Direct Normal Radiation', 'Diffuse Horizontal Radiation',\n",
    "        'Global Horizontal Illuminance', 'Direct Normal Illuminance',\n",
    "        'Diffuse Horizontal Illuminance', 'Zenith Luminance', 'Wind Direction',\n",
    "        'Wind Speed', 'Total Sky Cover', 'Opaque Sky Cover', 'Visibility',\n",
    "        'Ceiling Height', 'Present Weather Observation', 'Present Weather Codes',\n",
    "        'Precipitable Water', 'Aerosol Optical Depth', 'Snow Depth',\n",
    "        'Days Since Last Snowfall', 'Albedo', 'Liquid Precipitation Depth',\n",
    "        'Liquid Precipitation Quantity'\n",
    "    ]\n",
    "\n",
    "    # Leitura do arquivo\n",
    "    df = pd.read_csv(path, skiprows=8, names=columns)\n",
    "    \n",
    "    # Processamento de datas\n",
    "    df['Year'] = 2000\n",
    "    df['Hour'] = df['Hour[1-24]'] - 1\n",
    "    df['Datetime'] = pd.to_datetime(\n",
    "        df[['Year', 'Month', 'Day', 'Hour', 'Minute']],\n",
    "        format='%Y-%m-%d %H:%M'\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def inmet_to_pandas(file_path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega dados do INMET de arquivo CSV formatando datas e horas.\n",
    "\n",
    "    Processa colunas de data e hora para criar um índice datetime unificado.\n",
    "    Assume formato brasileiro DD/MM/YYYY na coluna 'Data' e HHMM em 'Hora (UTC)'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str | Path): Caminho para o arquivo CSV do INMET\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com dados processados e coluna datetime\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Se o arquivo não existir\n",
    "        ValueError: Se extensão inválida ou estrutura de dados incorreta\n",
    "        KeyError: Se colunas obrigatórias não estiverem presentes\n",
    "    \"\"\"\n",
    "    # Validação inicial do arquivo\n",
    "    path = Path(file_path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo INMET não encontrado: {file_path}\")\n",
    "    if path.suffix.lower() != \".csv\":\n",
    "        raise ValueError(\"Extensão inválida. Arquivo deve ser .csv\")\n",
    "\n",
    "    # Carregamento dos dados com tratamento de tipos\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            sep=';',\n",
    "            decimal=','\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Coluna obrigatória ausente: {e}\") from e\n",
    "\n",
    "    # Processamento da data com verificação de formato\n",
    "    date_parts = df['Data'].str.split('/', expand=True)\n",
    "    if date_parts.shape[1] != 3:\n",
    "        raise ValueError(\"Formato de data inválido. Esperado DD/MM/YYYY\")\n",
    "    \n",
    "    # Conversão para inteiros com tratamento de erros\n",
    "    try:\n",
    "        df = df.assign(\n",
    "            Day=date_parts[0].astype('int8'),\n",
    "            Month=date_parts[1].astype('int8'),\n",
    "            Year=date_parts[2].astype('int16'),\n",
    "            Hour=df['Hora (UTC)'] // 100,\n",
    "            Minute=0  # INMET não fornece minutos\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\"Valor numérico inválido nas colunas de tempo\") from e\n",
    "\n",
    "    # Criação da coluna datetime otimizada\n",
    "    try:\n",
    "        df['Datetime'] = pd.to_datetime(\n",
    "            df[['Year', 'Month', 'Day', 'Hour', 'Minute']],\n",
    "            format='%Y-%m-%d %H:%M'\n",
    "        )\n",
    "    except pd.errors.OutOfBoundsDatetime as e:\n",
    "        raise ValueError(\"Data fora do intervalo suportado (1677-2262)\") from e\n",
    "\n",
    "    return df[df[df.columns[2]].notna()]\n",
    "\n",
    "def set_wind_direction(wind_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converte direção angular do vento em orientação categórica (8 pontos cardeais).\n",
    "\n",
    "    Args:\n",
    "        wind_series (pd.Series): Série contendo ângulos de direção do vento em graus (0-360).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Série categórica com direções em português ('N', 'NE', ..., 'NO').\n",
    "\n",
    "    Exemplos:\n",
    "        >>> direcoes = pd.Series([0, 90, 180, 270, 350])\n",
    "        >>> set_wind_direction(direcoes)\n",
    "        0     N\n",
    "        1     L\n",
    "        2     S\n",
    "        3     O\n",
    "        4     N\n",
    "        dtype: category\n",
    "    \"\"\"\n",
    "    # Mapeamento de setores para direções\n",
    "    direcoes = ['N', 'NE', 'L', 'SE', 'S', 'SO', 'O', 'NO']\n",
    "    \n",
    "    # Ajuste para alinhar setores de 45° com os pontos cardeais\n",
    "    angulos_ajustados = (wind_series + 22.5) % 360\n",
    "    setores = np.floor(angulos_ajustados / 45)#.astype('int32')\n",
    "    \n",
    "    # Criar série categórica ordenada\n",
    "    return pd.Categorical(\n",
    "        values=pd.Series(setores).map(dict(enumerate(direcoes))),\n",
    "        categories=direcoes,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "def slice_dataframe(\n",
    "    dataframe: pd.DataFrame,\n",
    "    columns: list[str],\n",
    "    name: str = ''\n",
    ") -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Filtra colunas específicas do DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame original\n",
    "        columns (list[str]): Lista de colunas para manter\n",
    "        name (str): Nome para atribuir ao DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: DataFrame filtrado ou None se erro\n",
    "    \"\"\"\n",
    "    if not isinstance(dataframe, pd.DataFrame) or not isinstance(columns, list):\n",
    "        raise ValueError(\"Coluna não encontrada no DataFrame\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        filtered_df = dataframe[columns].copy()\n",
    "        filtered_df.attrs['Name'] = name\n",
    "        return filtered_df\n",
    "    except KeyError as e:\n",
    "        print(f\"Erro ao filtrar colunas: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_n_percent_rows(dataframe: pd.DataFrame, percent: float) -> int:\n",
    "    \"\"\"\n",
    "    Calcula número de linhas equivalente a uma porcentagem do total.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame de entrada\n",
    "        percent (float): Percentual desejado (0.0 a 1.0)\n",
    "\n",
    "    Returns:\n",
    "        int: Número de linhas equivalente à porcentagem\n",
    "    \"\"\"\n",
    "    if not isinstance(percent, (int, float)) or not 0 <= percent <= 1:\n",
    "        raise ValueError(\"Percentual deve ser numérico entre 0 e 1\")\n",
    "    \n",
    "    return int(dataframe.shape[0] * percent)\n",
    "\n",
    "\n",
    "def slice_sorted_dataframe(\n",
    "    dataframe: pd.DataFrame,\n",
    "    sort_by: str,\n",
    "    ascending: bool = True,\n",
    "    percent: float = 0.2,\n",
    "    name: str = ''\n",
    ") -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Ordena e seleciona top N% de um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame original\n",
    "        sort_by (str): Coluna para ordenação\n",
    "        ascending (bool): Ordem crescente/decrescente\n",
    "        percent (float): Percentual de linhas a selecionar\n",
    "        name (str): Nome para atribuir ao DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: DataFrame processado ou None se erro\n",
    "    \"\"\"\n",
    "    try:\n",
    "        n_rows = calculate_n_percent_rows(dataframe, percent)\n",
    "        sorted_df = dataframe.sort_values(\n",
    "            by=sort_by, \n",
    "            ascending=ascending\n",
    "        ).iloc[:n_rows].copy()\n",
    "        sorted_df.attrs['Name'] = name\n",
    "        return sorted_df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_as_csv(dataframe: pd.DataFrame, folder_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Salva DataFrame em arquivo CSV com nome específico.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame a ser salvo\n",
    "        folder_path (str): Pasta de destino\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se caminho inválido ou DataFrame vazio\n",
    "    \"\"\"\n",
    "    if not dataframe.empty and isinstance(dataframe, pd.DataFrame):\n",
    "        folder = Path(folder_path).resolve()\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "        file_path = folder / f\"{dataframe.attrs.get('Name', 'data')}.csv\"\n",
    "        dataframe.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame inválido ou vazio para exportação\")\n",
    "\n",
    "# definir pasta de trabalho\n",
    "epw_folder = '../epw_raw/'\n",
    "inmet_folder = '../inmet_raw/'\n",
    "export_folder = '../climate_csv/'\n",
    "\n",
    "# limpando o EPW\n",
    "iguape_old_epw = epw_to_pandas(\n",
    "    f'{epw_folder}BRA_SP_Iguape.869230_TMYx.2009-2023.epw'\n",
    ")\n",
    "\n",
    "iguape_epw = slice_dataframe(\n",
    "    dataframe=iguape_old_epw,\n",
    "    columns=[\n",
    "        'Datetime', 'Dry Bulb Temperature', 'Relative Humidity',\n",
    "        'Wind Speed', 'Wind Direction', 'Liquid Precipitation Depth'\n",
    "    ],\n",
    "    name='iguape_all_hours'\n",
    ")\n",
    "\n",
    "# renomeando as colunas\n",
    "iguape_epw.columns = [\n",
    "    'Datetime', 'Temp', 'Umi', 'Vel_vento', 'Dir_vento', 'Precipitacao'\n",
    "]\n",
    "\n",
    "# adicionar orientação da ventilação\n",
    "ori_vento = 'Ori_vento'\n",
    "iguape_epw[ori_vento] = set_wind_direction(iguape_epw['Dir_vento'])\n",
    "\n",
    "# salvar arquivo\n",
    "iguape_epw.attrs['Name'] = 'iguape_epw'\n",
    "save_as_csv(iguape_epw,export_folder)\n",
    "print(f'{iguape_epw.attrs[\"Name\"]} foi salvo.')\n",
    "\n",
    "del iguape_old_epw\n",
    "\n",
    "# limpando os arquivos INMET\n",
    "# definindo os arquivos para importação\n",
    "inmet_2019 = {'inmet_2019':('a712_iguape_2019a','a712_iguape_2019b')}\n",
    "inmet_2020 = {'inmet_2020':('a712_iguape_2020a','a712_iguape_2020b')}\n",
    "inmet_2021 = {'inmet_2021':('a712_iguape_2021a','a712_iguape_2021b')}\n",
    "inmet_2022 = {'inmet_2022':('a712_iguape_2022a','a712_iguape_2022b')}\n",
    "inmet_2023 = {'inmet_2023':('a712_iguape_2023a','a712_iguape_2023b')}\n",
    "inmet_2024 = {'inmet_2024':('a712_iguape_2024a','a712_iguape_2024b')}\n",
    "\n",
    "inmet_dados = (\n",
    "    inmet_2019,inmet_2020,inmet_2021,inmet_2022,inmet_2023,inmet_2024\n",
    ")\n",
    "\n",
    "# criar os dataframes\n",
    "for item in inmet_dados:\n",
    "    for key in item.keys():\n",
    "        df1 = inmet_to_pandas(f'{inmet_folder}{item[key][0]}.csv')\n",
    "        df2 = inmet_to_pandas(f'{inmet_folder}{item[key][1]}.csv')\n",
    "        # juntando os dataframes\n",
    "        df3 = pd.concat([df1,df2])\n",
    "        # dando um nome para o dataframe\n",
    "        df3.attrs['Name'] = key\n",
    "        # selecionando as colunas usadas\n",
    "        df3 = df3[[\n",
    "            'Datetime', 'Temp. Ins. (C)', 'Umi. Ins. (%)', 'Vel. Vento (m/s)',\n",
    "            'Dir. Vento (m/s)', 'Chuva (mm)'\n",
    "        ]]\n",
    "        # renomeando as colunas\n",
    "        df3.columns = [\n",
    "            'Datetime', 'Temp', 'Umi', 'Vel_vento', 'Dir_vento', 'Precipitacao'\n",
    "        ]\n",
    "\n",
    "        # adicionar orientação do vento\n",
    "        df3[ori_vento] = set_wind_direction(df3['Dir_vento'])\n",
    "        \n",
    "        # removendo as colunas vazias\n",
    "        df3 = df3[df3['Temp'].notnull()]\n",
    "        \n",
    "        save_as_csv(df3,export_folder)\n",
    "        print(f'{df3.attrs[\"Name\"]} foi salvo.')\n",
    "        \n",
    "        del df1, df2, df3\n",
    "\n",
    "# novos dataframes com os 10% mais quente e frio\n",
    "iguape_10p_cold = slice_sorted_dataframe(\n",
    "    dataframe=iguape_epw,\n",
    "    sort_by='Temp',\n",
    "    ascending=True,\n",
    "    percent=0.1,\n",
    "    name='iguape_cold_hours'\n",
    ")\n",
    "\n",
    "iguape_10p_hot = slice_sorted_dataframe(\n",
    "    dataframe=iguape_epw,\n",
    "    sort_by='Temp',\n",
    "    ascending=False,\n",
    "    percent=0.1,\n",
    "    name='iguape_hot_hours'\n",
    ")\n",
    "\n",
    "# salvar os DataFrame em csv\n",
    "for df in (iguape_10p_cold, iguape_10p_hot):\n",
    "    save_as_csv(df, export_folder)\n",
    "    # limpando a memoria\n",
    "    print(f'{df.attrs[\"Name\"]} foi salvo.')\n",
    "    del df\n",
    "\n",
    "print('.\\n.\\n.\\nCódigo concluído.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
